{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "#load the data\n",
    "train = pd.read_csv('data/train_prepared.zip')\n",
    "test = pd.read_csv('data/test_prepared.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare train data for modelling\n",
    "train_np = train.to_numpy()\n",
    "y_train = train_np[:,8]\n",
    "X_train = np.delete(train_np, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare test data for modelling\n",
    "test_np = test.to_numpy()\n",
    "y_test = test_np[:,8]\n",
    "X_test = np.delete(test_np, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "import sklearn.compose\n",
    "\n",
    "#Logistic regression\n",
    "model = sklearn.linear_model.LogisticRegression().fit(X_train, y_train)\n",
    "log_reg_predictions = model.predict(X_test)\n",
    "\n",
    "log_reg_accuracy = sklearn.metrics.accuracy_score(y_test, log_reg_predictions)\n",
    "print(log_reg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set = pd.read_csv('data/full_prepared.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare full dataset for modelling\n",
    "full_np = full_set.to_numpy()\n",
    "y_full = full_np[:,8]\n",
    "X_full = np.delete(full_np, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "#perform cross-validation with accuracy scores\n",
    "accuracy_scores = sklearn.model_selection.cross_val_score(sklearn.linear_model.LogisticRegression(), X_full, y_full, cv=4)\n",
    "print('Accuracy by cval: ', accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross-validation with roc auc scores with OvO scheme\n",
    "roc_auc_ovo_scores = sklearn.model_selection.cross_val_score(sklearn.linear_model.LogisticRegression(), X_full, y_full, cv=4,\n",
    "                         scoring='roc_auc_ovo')\n",
    "print('ROC AUC by cval: ', roc_auc_ovo_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross-validation with roc auc scores with OvR scheme\n",
    "roc_auc_ovr_scores = sklearn.model_selection.cross_val_score(sklearn.linear_model.LogisticRegression(), X_full, y_full, cv=4,\n",
    "                         scoring='roc_auc_ovr')\n",
    "print('ROC AUC by cval: ', roc_auc_ovr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, log_reg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute F1 scores\n",
    "f1_macro_score = sklearn.metrics.f1_score(y_test, log_reg_predictions, average='macro')\n",
    "f1_micro_score = sklearn.metrics.f1_score(y_test, log_reg_predictions, average='micro')\n",
    "print(f1_macro_score)\n",
    "print(f1_micro_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Logistic Regression model in another library to get the model summary\n",
    "import statsmodels.api as sm\n",
    "target = train.loc[:,\"ratchg\"]\n",
    "train_sm = train.drop(columns=['ratchg'], axis=1)\n",
    "model = sm.MNLogit(target, train_sm).fit()\n",
    "model.summary()\n",
    "model.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to improve Logistic Regreession performance with feature engineering (failed)\n",
    "transform = sklearn.compose.ColumnTransformer([(\"categorical\", sklearn.preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\"), [1,2,3,6])])\n",
    "\n",
    "X_train_poly = transform.fit_transform(X_train)\n",
    "X_test_poly = transform.transform(X_test)\n",
    "\n",
    "polynomial = sklearn.preprocessing.PolynomialFeatures(2, include_bias=False)\n",
    "X_train_poly = polynomial.fit_transform(X_train_poly)\n",
    "X_test_poly = polynomial.fit_transform(X_test_poly)\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression().fit(X_train_poly, y_train)\n",
    "log_reg_predictions = model.predict(X_test_poly)\n",
    "\n",
    "log_reg_accuracy = sklearn.metrics.accuracy_score(y_test, log_reg_predictions)\n",
    "print(log_reg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "\n",
    "#Decision tree model\n",
    "DT_model = sklearn.tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "DT_predictions = DT_model.predict(X_test)\n",
    "\n",
    "DT_accuracy = sklearn.metrics.accuracy_score(y_test, DT_predictions)\n",
    "print(DT_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute F1 scores for Decision Tree model\n",
    "f1_macro_score = sklearn.metrics.f1_score(y_test, DT_predictions, average='macro')\n",
    "f1_micro_score = sklearn.metrics.f1_score(y_test, DT_predictions, average='micro')\n",
    "print(f1_macro_score)\n",
    "print(f1_micro_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct confusion matrix for Decision Tree model\n",
    "confusion_matrix(y_test, DT_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross-validation with accuracy scores for Decision Tree model\n",
    "accuracy_scores = sklearn.model_selection.cross_val_score(sklearn.tree.DecisionTreeClassifier(), X_full, y_full, cv=4)\n",
    "print('Accuracy by cval: ', accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "#Random Forest model\n",
    "RF_model = sklearn.ensemble.RandomForestClassifier(oob_score=True).fit(X_train, y_train)\n",
    "        \n",
    "RF_predictions = RF_model.predict(X_test)\n",
    "\n",
    "RF_accuracy = sklearn.metrics.accuracy_score(y_test, RF_predictions)\n",
    "print(RF_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the oob score for Random Forest model\n",
    "print(RF_model.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute F1 scores for Random Forest model\n",
    "f1_macro_score = sklearn.metrics.f1_score(y_test, RF_predictions, average='macro')\n",
    "f1_micro_score = sklearn.metrics.f1_score(y_test, RF_predictions, average='micro')\n",
    "\n",
    "print(f1_macro_score)\n",
    "print(f1_micro_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct confusion matrix for Random Forest model\n",
    "confusion_matrix(y_test, RF_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2305800fefceda3f2e2d019a83e737014c066fed7151de411f61bfc53e80d6fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
